\chapter{Programmierparadigmen}

Zusammenfassung der Vorlesung "`Programmierparadigmen"' aus dem Wintersemester 2014.\footnote{\url{https://pp.info.uni-karlsruhe.de/lehre/WS201415/paradigmen/}}

\section{Funktionale Programmierung (S16)}

\subsection{Einführung: Funktionale Programmierung in Haskell}
\begin{itemize}
	\item Funktionale Programme sind kompakt, frei von Seiteneffekten, unabhängig von der Anweisungsreihenfolge
	\item Der Begriff \textit{Funktion} in Sprachen wie Haskell entspricht der mathematischen Sicht: Ausgaben hängen lediglich von Eingaben ab \(\rightarrow\) Auswertungen haben keinen Effekt auf Daten des Programms.
	\item Haskellprogramme sind Folgen von Funktionsdefinitionen
\end{itemize}

\subsection{Rekursion (S27)}
\begin{itemize}
	\item Auswertung: Zwischenausdrücke können mit Eingabegröße wachsen
	\item Speicherverbrauch in \(\mathcal{O}(n)\) bei \(\mathcal{O}(n)\) Aufrufen
	\item \textbf{Akkumulation}
	\begin{itemize}
		\item Übergebe Zwischenergebnisse in Hilfsparameter \texttt{acc}
		\item Speicherverbrauch in \(\mathcal{O}(1)\) bei \(\mathcal{O}(n)\) Aufrufen
	\end{itemize}
\end{itemize}

\subsubsection{Endrekursion (S30)}
\begin{itemize}
	\item Linearität: Eine Funktion heißt \textit{linear rekursiv}, wenn in jedem Definitionszweig nur ein rekursiver Aufruf vorkommt.
	\item Endrekursion: Eine linear rekursive Funktion heißt \textit{endrekursiv}, wenn in jedem Zweig der rekursive Aufruf nicht in andere Aufrufe eingebettet ist.
\end{itemize}


\subsection{Listen (S34)}
\begin{itemize}
	\item Eine Liste \texttt{(x:xs)} besteht immer aus Listenkopf \texttt{x} und Listenrest \texttt{xs}
\end{itemize}

\subsubsection{Pattern Matching (S37)}
\begin{itemize}
	\item Mehrere Gleichungen zur Definition einer Funktion
	\item Jede Gleichung gilt für Argumente mit speziellem Strukturmuster
	\item Überlappende Muster: Erste Gleichung wird angewandt
\end{itemize}


\subsection{Funktionen höherer Ordnung (S44)}

\subsubsection{Lambda-Notation (S45)}
\begin{itemize}
	\item Anonyme Funktionen und Funktionen höherer Ordnung möglich
	\item Beispiel: \(g(x,y)=x-\frac{y}{2} \longrightarrow\) \texttt{g = \textbackslash x y -> x - 2/y}
\end{itemize}

\subsubsection{Definition: Funktion höherer Ordnung (S47)}
Funktionen, die andere Funktionen als Parameter erhalten oder Funktionen als Rückgabewerte liefern, heißen Funktionen höherer Ordnung.

\subsubsection{Currying (S50)}
\begin{itemize}
	\item Ersetzung einer mehrstelligen Funktion durch Schachtelung einstelliger Funktionen.
	\item Jede Funktion erhält, wie oben erwähnt, nur ein Argument. Werden scheinbar mehrere Argumente definiert, so steckt immer Currying dahinter.
	\item Unterversorgung: Anwendung mehrstelliger Funktionen auf zu wenig Parameter
\end{itemize}

\textbf{Beispiel\footnote{\url{https://de.wikipedia.org/wiki/Currying\#Haskell}}}

\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Haskell]
addiere x y = x + y
addiere 1 3                -- ist aequivalent zu (addiere 1) 3
addiereZu2  = addiere 2
addiereZu2 1               -- 3
\end{lstlisting}

\subsubsection{Namensbindung (S54)}
\begin{itemize}
	\item Bindungsstrukte legen Bedeutung und Geltungsbereiche von Variablen fest
	\item Verdeckung: Innere Bindungen verdecken äußere
	\item \textbf{Bindung}
	\begin{itemize}
		\item \texttt{f x = x*x}: Bindung von \texttt{x} im Rumpf von \texttt{f}, globale Bindung von \texttt{f}
		\item \texttt{\textbackslash x -> x*x}: Bindung von \texttt{x} innerhalb des \(\lambda\)-Ausdrucks
	\end{itemize}
\end{itemize}

\subsubsection{Lokale Bindung (S57)}
\begin{itemize}
	\item Anwendung: Lokale Hilfsfunktionen
	\item \texttt{let} bindet stärker als \texttt{where}
\end{itemize}

\textbf{Beispiele}

\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Haskell]
energy m = let c = 299792458
           in m * c * c

energy m = m * c * c
  where c = 299792458
\end{lstlisting}

\subsection{Kombinatoren (S64)}

\subsubsection{Folds (S65)}
\begin{itemize}
	\item Anwendung einer Operation und eines Initialwertes auf eine Liste
	\item \textbf{Beispiel Summenberechnung}
	\begin{itemize}
		\item \texttt{sum = (+) 0}
		\item Berechnung mittels \texttt{foldr}: \texttt{(1 + (2 + (3 + (4 + 0))))} (rechts-geklammert)
		\item Berechnung mittels \texttt{foldl}: \texttt{((((1 + 0) + 2) + 3) + 4)} (links-geklammert)
	\end{itemize}
	\item Anwendung: Komplexe Funktionen als Kombination einfacher Funktionen
\end{itemize}

\subsubsection{Kombination von Listen (S67)}
\begin{itemize}
	\item Zusammenfügen von Listen per Reißverschluss: \texttt{zip = zipWith (,)}
	\item \texttt{zipWith} definiert eine Zusätzliche Operation
	\item Bricht ab, wenn eine der Listen keine weiteren Elemente enthält
\end{itemize}

\subsubsection{List Comprehensions (S67)}
\begin{itemize}
	\item Automatisiertes Erzeugen von Listen, basierend auf bereits existierenden Listen
	\item Inspiriert durch die mathematische Mengenschreibweise: \texttt{s = {[} 2 * x {|} x <- {[}0..{]}, x\textasciicircum 2 > 3 {]} } \footnote{\url{https://en.wikipedia.org/wiki/List_comprehension\#Haskell}}
	\item Multidimensionale Liste: \texttt{s = {[} 2*x*y {|} x <- {[}0..{]}, x\textasciicircum2 > 3, y <- {[}1,3..x{]}, y\textasciicircum2 < 100-x\textasciicircum2 {]}}
	\item Bei mehrdimensionaler Eingabe: Nur die erste Liste gegen Unendlich laufen lassen (siehe Klausur WS2014, Aufgabe 1)
\end{itemize}


\subsection{Lazy Evaluation (S70)}

\subsubsection{Auswertung (S73)}
\begin{itemize}
	\item Strukturierte Daten: Nur auswerten, falls wirklich benötigt wird
	\item Duplizierte Argumente: Auswertung maximal einmal (\textit{sharing})
	\item Pattern-Matching: So weit wie nötig, bis passendes Muster gematched
	\item Boolsche Operatoren: Auswertung bis zum ersten \textit{false} (\textit{short-circuit-Auswertung})
	\item \textbf{Nachteile}
	\begin{itemize}
		\item Erschwerte Fehlersuche
		\item Fehler, die beim Testen nicht beachten wurden, tauchen eventuell später im Betrieb auf
	\end{itemize}
\end{itemize}


\subsection{Typen (S82)}
\begin{itemize}
	\item Haskell ist statisch typisiert
	\item Jeder gültige Ausdruck hat immer einen Typ und wertet immer zu gültigen Werten dieses Typs aus
	\item Schreibweise: \texttt{e :: t} falls Ausdruck \texttt{e} und Typ \texttt{t}
	\item Untypisierbare Ausdrücke erzeugen Übersetzerfehler
	\item Haskell erkennt den korrekten Typ (fast immer) zuverlässig, optional manuelle Deklaration möglich
\end{itemize}

\subsubsection{Polymorphe Typen (S86)}
\begin{itemize}
	\item Der Listen-Typ sind polymorph, die Typvariable \texttt{{[}t{]}} steht auch für Nicht-Basistypen
	\item Typvariablen parametrisieren polymorphe Typen
	\item Typkonstruktoren wie \texttt{{[} {]}} erzeugen neue Typen aus bestehenden
	\item Funktionstypen sind ebenfalls polymorph
\end{itemize}

\subsubsection{Beispiele}
\begin{itemize}
	\item Typen mehrstelliger Funktionen: \texttt{f x y = x * y, f :: Integer -> Integer -> Integer}
	\item Typen eingebauter Operatoren: \texttt{(<=) :: Integer -> Integer -> Bool}
	\item Tupel: \texttt{(3, True) :: (Integer, Bool); (not, 7) :: (Bool -> Bool, Integer)}
\end{itemize}

\subsubsection{Typinferenz (S91)}
Errechnen der Typen durch den Compiler, dadurch entstehen kompakte Programme, die trotzdem typsicher sind. Manuelle Deklaration ist dennoch möglich.

\subsubsection{Typsynonyme (S93)}
Ableiten neuer Typen aus vorhandenen. Z.B. \texttt{type String = {[}char{]}} (kann die Lesbarkeit erhöhen). Es werden keine explizit neuen Typen erzeugt.

\subsubsection{Typen bei der Fehlersuche (S94)}
\begin{itemize}
	\item Typendeklarationen können beim Lokalisieren von Programmfehlern helfen
	\item Beabsichtigten Typ der Funktion deklarieren
	\item \textbf{Beispiel}
	\begin{itemize}
		\item \texttt{isDigit :: Char -> Bool}\\\texttt{isDigit c = isIn c "0123456789"}
		\item \texttt{*Main> isDigit '3'} würde zu einem Typfehler führen
	\end{itemize}
\end{itemize}

\subsubsection{Mengen (S95)}
\begin{itemize}
	\item Mengen bestehen aus dem Typ \texttt{Set = ...} sowie Funktionen zum Iterieren, Einfügen, Löschen, Vergleichen, usw.
	\item Einfachste Implementierung als Listen: \texttt{type Set t = {[} {]}}
\end{itemize}


\subsection{Algebraische und rekursive Datentypen (S102)}

\subsubsection{Produkttypen}
Typen mit mehreren Komponenten.

\subsubsection{Nachteile von Tupeln (S103)}
\begin{itemize}
	\item Typsynonyme: Typen mit mehreren Komponenten. Beispiel: Personen mit Name und Alter \texttt{type Person = (String, Int)}
	\item Nachteil: Bedeutung von Werten nicht explizit; ungewollte Verwendung gleicher Tupel (z.B. \texttt{(String, Int)}) mit verschiedener Bedeutung
\end{itemize}

\subsubsection{Algebraische Datentypen (S104)}
\begin{itemize}
	\item Verwendung des Schlüsselwortes \texttt{data} statt \texttt{type} zur definition \textit{neuer} Typen
	\item Einfachste Anwendung: Aufzählungstypen. Funktionsimplementierung über Pattern Matching\\\\
	\begin{minipage}{\linewidth}
	\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Haskell]
data Temp   = Cold | Hot
data Season = Spring | Summer | Autumn | Winter

weather :: Season -> Temp
weather spring = Cold
weather summer = Hot
weather autumn = Cold
weather winter = Cold
	\end{lstlisting}
	\end{minipage}
	\item Alternativ-Typen mit mehreren Konstruktoren\\\\
	\begin{minipage}{\linewidth}
	\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Haskell]
data Shape = Circle Double | Rectangle Double Double | Square Double

-- Konstruktor
dinA4 = Rectangle 210.0 297.0

-- Flaechenberechnung
area (Circle r)      = pi*r*r
area (Rectangle a b) = a*b
area (Square a)      = a*a
	\end{lstlisting}
	\end{minipage}
	\item Optionale Werte
	\begin{itemize}
		\item Anwendung: Funktionen, die bei bestimmten Eingaben fehlschlagen können (Vgl. \texttt{null} in Java)
		\item Auswertung/Abfangen über Pattern-Matching
	\end{itemize}
	\begin{minipage}{\linewidth}
	\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Haskell]
data Maybe t = Nothing | Just t
	\end{lstlisting}
	\end{minipage}
\end{itemize}

\subsection{Anwendung algebraischer Datentypen (S108)}
\begin{itemize}
	\item \textbf{Algebraischer Datenstrukturen ermöglichen}
	\begin{itemize}
		\item Implementierung von Datenstrukturen
		\item Modellierung problemspezifischer Daten
	\end{itemize}
	\item \textbf{Einsatz von Pattern-Matching}
	\begin{itemize}
		\item Erleichtert Umsetzung komplexer Algorithmen
		\item Besonders für baumartige Strukturen
	\end{itemize}
	\item \textbf{Anwendungsbeispiele}
	\begin{itemize}
		\item Datenstrukturen: Maps, Bäume, Rot-Schwarz-Bäume \\\\
		\begin{minipage}{\linewidth}
		\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Haskell]
data Tree = Leaf | Node (Tree t) t (Tree t)
someTree  = Node (Node Leaf 1 Leaf) 3 Leaf
		\end{lstlisting}
		\end{minipage}
		\item Polymorphe Datentypen
		\item Fehlerbehandlung
		\item Termersetzungssysteme
	\end{itemize}
\end{itemize}


\subsection{Typklassen (S124)}
Motivation am Beispiel \textit{Quicksort}: Algorithmus prinzipiell für alle (sortierbaren) Element-Typen umsetzbar.

\subsubsection{Implementierungsansätze (S126)}
\begin{enumerate}
	\item Eigene Funktion je Datentype: Softwaretechnisch katastrophal\\\\
	\begin{minipage}{\linewidth}
	\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Haskell]
qsortI :: [Integer] -> [Integer]
qsortD :: [Double]  -> [Double]
	\end{lstlisting}
	\end{minipage}
	\item Umsetzung als polymorphe Funktion: Funktioniert nicht, da nicht alle Typen \texttt{t} sortierbar sind.\\\\
	\begin{minipage}{\linewidth}
	\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Haskell]
qsort :: [t] -> [t]
	\end{lstlisting}
	\end{minipage}
	\item Lösung: Polymorphe Funktion mit Typeinschränkung\\\\
	\begin{minipage}{\linewidth}
	\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Haskell]
qsort :: Ord t => [t] -> [t]
	\end{lstlisting}
	\end{minipage}
\end{enumerate}

\subsubsection{Standard-Typklassen (S127)}
\begin{itemize}
	\item Fassen Typen anhand auf ihnen definierter Operationen zusammen
	\item Ähneln grob Java-Interfaces
	\item \texttt{Beispiele}
	\begin{itemize}
		\item Äquivalenzrelation: \texttt{Eq t} (vergleichbar)
		\item Geordnete Typen: \texttt{Ord t} (sortierbar)
		\item Numerische Typen: \texttt{Num t} (berechenbar)
		\item Anzeigbare Typen: \texttt{Show t}
		\item Aufzählungstypen: \texttt{Enum t} (beispielsweise Vorgänger oder Nachfolger berechenbar)
	\end{itemize}
\end{itemize}

\subsubsection{Typklassendefinition (S128)}
\begin{minipage}{\linewidth}
\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Haskell]
-- Typklassendefinition: Eq t
class (Eq t) where
	(==) :: t -> t -> Bool
	(/=) :: t -> t -> Bool

-- Typklasseninstanziierung: Gleichheit von Bool
instance (Eq Bool) where
	True  == True  = True
	False == False = True
	False == True  = False
	True  == False = False

-- oder alternativ
instance (Eq Bool) where
	True  /= True  = False
	False /= False = False
	False /= True  = True
	True  /= False = True
\end{lstlisting}
\end{minipage}

\subsubsection{Automatische Instanziierung (S129)}
\begin{minipage}{\linewidth}
\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Haskell]
data Shape = Circle Double | Rectangle Double Double | Square Double deriving Eq

-- Verschiedene Konstruktoren ergibt verschiedene Werte
Circel 1      == Square 1 $\rightarrow$ False
Rectangle 1 1 == Square 1 $\rightarrow$ False

-- Gleicher Konstruktor, verschiedene Werte ergibt verschiedene Werte
Circle 1 == Circle 3 $\rightarrow$ False

-- Gleicher Konstruktor, gleiche Werte ergibt gleiche Werte
Square 2 == Square 2  $\rightarrow$ True
\end{lstlisting}
\end{minipage}

\subsubsection{Vererbung von Typklassen (S130)}
Typklassen sind vererbbar. Beispielsweise ist jede Instanz von \texttt{Ord} auch eine Instanz von \texttt{Eq}.



\section{Theoretische Grundlagen (S153)}
Kalküle sind minimalistische Programmiersprachen zur Beschreibung von Berechnungen.	

\subsection{Der untypisierte $\lambda$-Kalkül (S159)}
\begin{itemize}
	\item Turing-mächtiges Modell funktionaler Programme zur Beschreibung sequentieller imperativer Konstrukte
	\item Linksassoziative Funktionsanwendung
	\item \(\lambda\)-Term: Ein Term der Form \texttt{(\(\lambda\)x.\(t_1\))\(t_2\)}
	\item \textbf{\(\alpha\)-Äquivalenz}
	\begin{itemize}
		\item \(t_1\) und \(t_2\) heißen \(\alpha\)-äquivalent, wenn \(t_1\) in \(t_2\) durch konsistente Umbenennung der \(\lambda\)-gebundenen Variablen überführt werden kann
		\item Funktionsbezeichnungen dürfen nicht geändert werden
		\item Beispiel: \texttt{\(\lambda\)x. (\(\lambda\)z. f(\(\lambda\)y. z y) x) = \(\lambda\)y. (\(\lambda\)x. f(\(\lambda\)z. x z) y)}
	\end{itemize}
	\item \textbf{\(\eta\)-Äquivalenz (S160)}
	\begin{itemize}
		\item Zwei Funktionen genau dann gleich sind, wenn sie für alle Argumente dasselbe Resultat liefern\footnote{\url{https://de.wikipedia.org/wiki/Lambda-Kalkül\#.CE.B7-Konversion}}
		\item Terme \texttt{\(\lambda\)x. f x} und \texttt{f} heißen \(\eta\)-äquivalent, falls \texttt{x} eine nicht-freie Variable von \texttt{f} ist
	\end{itemize}
\end{itemize}

\subsubsection{$\beta$-Reduktion (S161)}
\begin{itemize}
	\item Formalisiert das Konzept der Funktionsanwendung
	\item Anwendung ausschließlich von links nach rechts
	\item Eine \(\beta\)-Reduktion entspricht der Ausführung der Funktionsanwendung auf einem Redex: \texttt{(\(\lambda\)x.\(t_1\))\(t_2 \Rightarrow\) \(t_1\){[} x \(\mapsto t_2\) {]}}
	\item Volle \(\beta\)-Reduktion: Jeder Redex kann reduziert werden
	\item \textbf{Beispiele}
	\begin{itemize}
		\item \texttt{(\(\lambda\)x.x)y \(\Rightarrow\) x{[} x \(\mapsto\) y {]} = y}
		\item \texttt{(\(\lambda\)x.x (\(\lambda\)x.x))(y z) \(\Rightarrow\) (x (\(\lambda\)x.x)){[} x \(\mapsto\) y z {]} = (y z)(\(\lambda\)x.x)}
	\end{itemize}
	\item \textbf{Braucht man primitive Operationen?}
	\begin{itemize}
		\item Nein, nicht unbedingt. Beispiel: \texttt{let}
		\item \texttt{let x = \(t_1\) in \(t_2\)} wird zu \texttt{(\(\lambda\)x.\(t_2\)) \(t_1\)}
		\item \texttt{let x = g y in f x = (\(\lambda\)x.f x)(g y) \(\Rightarrow\) f(g y)}
	\end{itemize}
\end{itemize}

\subsubsection{Kodierung natürlicher Zahlen (S172)}
\begin{itemize}
	\item Einbettung von Daten und Operationen in den \(\lambda\)-Kalkül
	\item Eine (natürliche) Zahl drückt aus, wie oft die Funktion \texttt{s} angewendet wird
	\item \textbf{Church-Zahlen}
	\begin{itemize}
		\item \texttt{\(c_0\) = \(\lambda\)s. \(\lambda\)z. z}
		\item \texttt{\(c_1\) = \(\lambda\)s. \(\lambda\)z. s z}
		\item \texttt{\(c_2\) = \(\lambda\)s. \(\lambda\)z. s (s z)}
		\item \texttt{\(c_3\) = \(\lambda\)s. \(\lambda\)z. s (s (s z))} \\ \(\vdots\)
		\item \texttt{\(c_n\) = \(\lambda\)s. \(\lambda\)z. \(s^n\) z}
	\end{itemize}
\end{itemize}

\subsubsection{Kodierung boolscher Werte (S174)}
\begin{itemize}
	\item \texttt{True} und \texttt{False} wird zu \texttt{\(c_{true}\) = \(\lambda\)t. \(\lambda\)f. t} und \texttt{\(c_{false}\) = \(\lambda\)t. \(\lambda\)f. f}
	\item \texttt{True} gibt den ersten Wert zurück, \texttt{false} den zweiten \(\rightarrow\) ermöglicht Entscheidungen
	\item \texttt{if \_ then \_ else \_} wird zu \texttt{\(\lambda\)a. a}. Beispielsweise wird aus \texttt{if True then x else y}: \texttt{(\(\lambda\)a. a) (\(\lambda\)t. \(\lambda\)f. t) x y \(\Rightarrow\) (\(\lambda\)t. \(\lambda\)f. t) x y \(\Rightarrow\) (\(\lambda\)f. x) y}
	\item \texttt{\(b_1\) \&\& \(b_2\)} wird zu \texttt{if \(b_1\) then \(b_2\) else False}
	\item \texttt{True \&\& True} ergibt: \texttt{(\(\lambda\)a. a) \(c_{true}\) \(c_{true}\) (\(\lambda\)t. \(\lambda\)f. t)}
\end{itemize}

\subsubsection{Divergenz (S175)}
\begin{itemize}
	\item Terme, die nicht zu einer Normalform auswerten, divergieren. Diese modellieren unendliche Ausführungen
	\item Beispiel: \texttt{\(\lambda\)x. x x} wendet sein Argument auf das Argument selbst an und reproduziert sich selbst. \texttt{\(\omega\) = (\(\lambda\)x. x x)(\(\lambda\)x. x x) \(\Rightarrow\) (\(\lambda\)x. x x)(\(\lambda\)x. x x)}
\end{itemize}

\subsubsection{Rekursionsoperator (S177)} % TODO
\begin{itemize}
	\item \texttt{\(\hat{f}\)} reproduziert sich ein jedem Schritt zusätzlich
	\item \texttt{Y \(\hat{f}\) = (\(\lambda\)f. (\(\lambda\)x. f (x x))(\(\lambda\)x. f (x x))) \(\hat{f}\)}
\end{itemize}

\subsubsection{Auswertungsstrategien (S182)}
\begin{itemize}
	\item \textbf{Auswertungsstrategien}
	\begin{itemize}
		\item Normalenreihenfolge: Immer der linkeste, äußerste Redex wird reduziert (S170)
		\item \textbf{Call-by-Name}
		\begin{itemize}
			\item Reduziere linkesten, äußersten Redex. Aber nur, falls nicht von einem \(\lambda\) umgeben
			\item Ituitiv: Reduziere Argumente erst, wenn benötigt
			\item Standardauswertungsstrategie für Funktionen/Konstruktoren
		\end{itemize}
		\item \textbf{Call-by-Value}
		\begin{itemize}
			\item Reduziere linkesten Redex, der nicht von einem \(\lambda\) umgeben ist und dessen Argument kein Wert ist
			\item Intuitiv: Argumente vor Funktionsaufruf auswerten
			\item Auswertungsstrategie vieler Sprachen: Java, C, Scheme, ML, etc.
		\end{itemize}
	\end{itemize}
\end{itemize}


\subsection{Typsysteme (S192)}
\begin{itemize}
	\item \textit{Typen} legen die möglichen Werte von Variablen, Operationen und Operanden fest. Beispiel: Integer, Float, String
	\item Statisch typisierte Sprachen: Jede Variable/jeder Ausdruck hat einen vom Compiler bestimmbaren Typ. Beispiel: Java, Haskell, C++
	\item Dynamisch typisierte Sprachen: Typ von Variablen kann sich zur Laufzeit ändern. Beispiele: JavaScript, Python, PHP
	\item \textbf{Vorteile von Typsystemen}
	\begin{itemize}
		\item Code ist verständlicher
		\item Compiler kann effizienteren Code erzeugen
		\item Typsicherheit: Abstürze wegen falscher Typen zur Laufzeit unmöglich
	\end{itemize}
	\item Typklassen definieren Funktionen, die für jede Instanz der Typklasse aufgerufen werden können
	\item Man kann eine Instanz für jeden Typ erstellen, indem man die Funktionen der Typklasse für den jeweiligen Typ definiert
	\item Beispiel: Vergleichsoperator (\texttt{==})
\end{itemize}


\subsubsection{Typherleitung (S196)} % TODO
\begin{itemize}
	\item Nachweis von Herleitbarkeit als Herleitungsbaum
	\item Die Struktur des Herleitungsbaums wird durch den \(\lambda\)-Term bestimmt
	\item Zu jedem Subterm genau eine passende Regel: \texttt{App, Var, Abs oder Const}
	\item \texttt{t} ist typisierbar im Kontext \(\Gamma\), falls \(\tau\) mit \(\Gamma\vdash t_2~:~\tau_2\) exisitiert
	\item Beispiel mit Ableitungsbaum auf Folie 196
	\item \textbf{Beispiele zum direkten Ablesen}
	\begin{itemize}
		\item \texttt{\(\lambda\)f. \(\lambda\)x. f x \\ x: \(\alpha\) \\ f x: \(\beta\) \(\Rightarrow\) f: \(\alpha\) \(\rightarrow\) \(\beta\) \\ \(\lambda\)x. f x: \(\alpha\) \(\rightarrow\) \(\beta\) \\ \(\lambda\)f. \(\lambda\)x. f x: (\(\alpha\) \(\rightarrow\) \(\beta\)) \(\rightarrow\) \(\alpha\) \(\rightarrow\) \(\beta\)}
		\item \texttt{\(\lambda\)o. \(\lambda\)f. \(\lambda\)g. \(\lambda\)x. o (f g) (g x) \\ x: \(\alpha\) \\ g x: \(\beta\) \(\Rightarrow\) g: \(\alpha\) \(\rightarrow\) \(\beta\) \\ f x: \(\gamma\) \(\Rightarrow\) f: \(\alpha\) \(\rightarrow\) \(\gamma\) \\ o (f x) (g x): \(\delta\) \(\Rightarrow\) \(\gamma\) \(\rightarrow\) \(\beta\) \(\rightarrow\) \(\delta\) \\ \(\lambda\)o. \(\lambda\)f. \(\lambda\)g. \(\lambda\)x. o (f g) (g x): (\(\gamma\) \(\rightarrow\) \(\beta\) \(\rightarrow\) \(\delta\)) \(\rightarrow\) (\(\alpha\) \(\rightarrow\) \(\gamma\)) \(\rightarrow\) (\(\alpha\) \(\rightarrow\) \(\beta\)) \(\rightarrow\) \(\alpha\) \(\rightarrow\) \(\delta\) \(\Rightarrow\)  (\(\alpha\) \(\rightarrow\) \(\beta\) \(\rightarrow\) \(\gamma\)) \(\rightarrow\) (\(\delta\) \(\rightarrow\) \(\alpha\)) \(\rightarrow\) (\(\delta\) \(\rightarrow\) \(\beta\)) \(\rightarrow\) \(\delta\) \(\rightarrow\) \(\gamma\)}
		\item \textbf{Typschema einer \texttt{let}-gebundenen Variable \texttt{f}}
		\begin{itemize}
			\item \texttt{G = \(\lambda\)y. let f = \(\lambda\)x. x 0 in f (\(\lambda\)z. y)}
			\item Lösung: Typschema für \texttt{f} in \texttt{G: f: \(\forall\)\(\alpha\). (int \(\rightarrow\) \(\alpha\)) \(\rightarrow\) \(\alpha\)}
		\end{itemize}
	\end{itemize}
\end{itemize}

\subsubsection{Untypisierbare \(\lambda\)-Terme (S197)}
\begin{itemize}
	\item Nicht alle sicheren Programme sind typisierbar \(\rightarrow\) Typsystem nicht vollständig bzgl. \(\beta\)-Reduktion
	\item Beispiel: \texttt{(\(\lambda\)x. x + 42) true} ist nicht typisierbar
	\item Die Korrektheit des Typsystems ist per Induktion über die Typsystemregeln beweisbar (S198)
\end{itemize}


\subsection{Polymorphie (S199)}
\begin{itemize}
	\item Polymorphe Funktionen: Verhalten hängt nicht vom konkreten Typ \(\tau\) der Elemente ab und haben unendlich viele Typen
	\item Beispiel: Operationen auf Containern (Zusammenfügen von Listen)
\end{itemize}

\subsubsection{\texttt{let}-Polymorphismus (S201)}
\begin{itemize}
	\item Beispielprogramm P: \texttt{let f = \(\lambda\)x. 2 in f (f true)}
	\item \texttt{f} ist eine polymorphe Hilfsfunktion: Anwendung erst auf \texttt{true}, dann auf \texttt{2}
	\item Typisierung so nicht möglich. Daher: \texttt{let x = \(t_1\) in \(t_2\)} als neues Konstrukt im \(\lambda\)-Kalkül. Neue Typregeln mit \textit{Typschemata}
	\item \textbf{Typschemata (S202)}
	\begin{itemize}
		\item Ein Typ der Gestalt \(\forall\alpha_1.\forall\alpha_2.~...~\forall\alpha_n.~\tau\) heißt Typschema
		\item Es bindet freie Typvariablen \(\alpha_1,...,\alpha_n\) in \(\tau\)
		\item Beispiel: \(\forall\alpha.~\alpha\rightarrow\alpha\) steht für unendlich viele Typen
		\item Ausführliches Ableitungsbeispiel auf Folie S205 % TODO
	\end{itemize}
	\item Flexibel einsetzbar, trotzdem bleibt Typsicherheit garantiert
\end{itemize}


\section{Logische Programmierung (S210)}
Prolog-Programme bestehen aus einer Datenbasis, deren Einträge sich Fakten und Regeln nennen. Der Benutzer formuliert Anfragen an diese Datenbasis. Der Prolog-Interpreter benutzt die Fakten und Regeln, um systematisch eine Antwort zu finden. Ein positives Resultat bedeutet, dass die Anfrage logisch ableitbar ist. Ein negatives Resultat bedeutet nur, dass aufgrund der Datenbasis keine Ableitung gefunden werden kann.\footnote{\url{https://de.wikipedia.org/wiki/Prolog_(Programmiersprache)\#Grundprinzip}}

\subsection{Einführung in Prolog (S211)}
\begin{itemize}
	\item Situationsbeschreibung sowie Definition von Objekten und Beziehungen zwischen Objekten. Prolog-Programme definieren eine Liste von Regeln und Fakten
	\item Elemente: \textit{Atome} (z.B. \texttt{hans, inge, fritz, fisch}), \textit{Zahlen (z.B. \texttt{3, 4.5})}, \textit{Variablen} (z.B. \texttt{X, Y, \_X, X1, Fisch}) oder \textit{Termlisten (z.B. \texttt{3, 4.5, X, fritz})}
\end{itemize}

\subsubsection{Abfragen (S217)}
\begin{itemize}
	\item Alle Fakten werden zur Laufzeit in einer Datenbank gehalten
	\item Abfragen per \texttt{?}: z.B. \texttt{?liebt(fritz,fisch)}
	\item \textbf{Mehrfachlösungen}
	\begin{itemize}
		\item Durchsuche Datenbank von vorne nach hinten
		\item Versuche jeweils, Abfrageparameter mit Datenbankfaktor zu unifizieren
		\item Wenn Variablen übergeben werden, dann werden diese gefüllt. Es wird immer die erste Lösung zurückgegeben
		\item Bei Bedarf kann nach weiteren Lösungen gesucht werden
	\end{itemize}
	\item \textbf{Konjunktion von Abfragen}
	\begin{itemize}
		\item Konjunktion von Teilzielen getrennt durch Komma, entspricht logischem \(\wedge\)
		\item Erfülle Teilziele von links nach rechts und nehme jeweils erstes Ergebnis
		\item Mehrere Ergebnisse: Fahre mit dem ersten Ergebnis bis zum Ende fort, prüfe danach weitere Ergebnisse
		\item Nach Erfüllung eines Teilziels: Nächstes Teilziel erbt Instanziierung
	\end{itemize}
\end{itemize}

\subsubsection{Regeln (S222)}
\begin{itemize}
	\item Aufbau: Regelkopf (1 Term) und Regelrumpf (1+ Terme): \texttt{term :- termlist .}
	\item \texttt{:-} liest sich als \textit{wenn}, Kommata als \textit{und}
	\item \textbf{Beispiele}
	\begin{itemize}
		\item "`Wenn Inge X liebt und wenn X Fisch liebt, dann liebt Hugo X"':\newline\texttt{liebt(hugo,X) :- liebt(inge,X),liebt(X,fisch)}
		\item "`Wenn es jemanden gibt, der Fisch mag, dann liebt Emil Erna"':\newline\texttt{liebt(emil,erna) :- liebt(X,fisch)}
	\end{itemize}
\end{itemize}

\subsubsection{Logische Programmierung ist anders (S225)}
\begin{itemize}
	\item Keine herkömmlichen Variablen
	\item Prädikate liefern außer ihrer Erfüllbarkeit keinen Ergebniswert
	\item Aber Unifikation und Backtracking eingebaut
	\item Sehr gut geeignet für Such- und Constraintprobleme, weniger für Berechnungen
\end{itemize}


\subsection{Backtracking (S226)}
\begin{itemize}
	\item Visualisierung durch einen Ausführungsbaum
	\item Jedes Teilziel wird als Box mit vier Ein- bzw. Ausgängen dargestellt
\end{itemize}

\subsubsection{Der Algorithmus informell (S228)}
\begin{enumerate}
	\item Anlegen und erstmaliges Betreten der Box durch den \texttt{call}-Eingang beim ersten Aufruf des Teilziels
	\item Falls keine passende Regel gefunden wird, wird die Box durch den \texttt{fail}-Ausgang verlassen und gelöscht
	\item Für eine passende Regel werden Kind-Boxen für Teilziele im Regelrumpf angelegt. Die Box wird durch den \texttt{success}-Ausgang verlassen. Dieser verweist auf den \texttt{call}-Eingang der ersten Kindbox
	\item Falls keine Kinder existieren (Fakt), verweist \texttt{success} auf den \texttt{call}-Eingang des nächsten Teilziels
	\item Der \texttt{fail}-Ausgang verweist auf den \texttt{redo}-Eingang des vorherigen Teilziels
	\item Wird eine Box durch den \texttt{redo}-Eingang betreten, werden mit Hilfe des Choice Points weitere anwendbare Regeln gesucht. Falls kein Choice Point existiert, wird die Box durch \texttt{fail}
	\item Der \texttt{fail}-Ausgang der obersten/ersten Box erzeugt die Ausgabe \texttt{no}
	\item Der \texttt{success}-Ausgang der rechtest-untersten/letzten Box gib Substitution aus. Falls der Benutzer eine alternative Lösungen anfordert, wird die Box durch \texttt{redo} wieder betreten
\end{enumerate}


\subsection{Arithmetik und Listen (S230)}

\subsubsection{Listen: \texttt{{[}X{|}Y{]}} (S231)}
\begin{itemize}
	\item \texttt{X} ist das erste Element der Liste (\textit{head}), \texttt{Y} ist der Rest der Liste (\textit{tail}), \texttt{{[}{]}} bezeichnet die leere Liste
	\item \texttt{Y} muss nicht instanziiert sein
	\item Listen können von vorne aufgebaut werden (im Gegensatz zu Haskell)
	\item \textbf{Listenfunktionen}
	\begin{itemize}
		\item \texttt{member (S232)}
		\begin{itemize}
			\item Berechnet, ob ein Element in der Liste vorkommt
			\item \texttt{member(X, {[}X{|}R{]}).} \\ \texttt{member(X, {[}Y{|}R{]}) := member(X,R).}
		\end{itemize}
		\item \texttt{append (S232)}
		\begin{itemize}
			\item Fügt zwei Listen zusammen (Konkatenation)
			\item Wenn die Konkatenation von \texttt{R} und \texttt{L} die Liste \texttt{T} ergibt, dann ergibt die Konkatenation von \texttt{{[}X{|}R{]}} und \texttt{L} die Liste \texttt{{[}X{|}T{]}}.
			\item \texttt{append({[]}, L, L).} \\ \texttt{append({[}X{|}R{]}, L, {[}X{|}T{]}) :- append(R, L, T).}
			\item Beispiel: \texttt{?append({[}1, 2, 3, 4{]}, {[}2, 3, 4, 5{]}, X).} ergibt \texttt{X = {[}1, 2, 3, 4, 2, 3, 4, 5{]}}
		\end{itemize}
		\item \texttt{rev (S234)}
		\begin{itemize}
			\item Naiver Ansatz: Eine nichtleere Liste wird invertiert, in dem man rekursiv den Listenrest invertiert und jeweils die Listenköpfe davor hängt
			\item Ineffizient, da in jedem Schritt die neue Liste durchlaufen und kopiert werden muss, um ein neues Element anzuhängen
			\item Alternativ: Nutze Akkumulator zum Zwischenspeichern des Ergebnisses
		\end{itemize}
		\item \texttt{Quicksort (S236)}
		\item \texttt{permute (S237)}: Erzeugt alle möglichen Permutationen einer Liste
	\end{itemize}
\end{itemize}

\subsubsection{Arithmetik (S238)}
\begin{itemize}
	\item Reines Prolog kann alle berechenbaren Funktionen verarbeiten, Prädikate werden über Atome dargestellt. In der Praxis können Arithmetik/Datentypen trotzdem nützlich sein
	\item Zuweisung per Teilziel: \texttt{is}
	\item Unterschied zur normalen Resolution: Variablen im \textit{rechten} Term müssen instanziiert sein \(\rightarrow\) nur vorwärts anwendbar
\end{itemize}

\subsubsection{Funktionen (S239)}
\begin{itemize}
	\item Funktionen in Prolog als Prädikate
	\item Prädikate tragen außer der Erfüllbarkeit keinen Rückgabewert \(\rightarrow\) Rückgabewert als zusätzliche, uninstanziirte Variable
	\item Formal ähnlich zum Pattern Matching
\end{itemize}

\subsubsection{Generate und Test (S241)}
Prolog ist besonders gut:
\begin{itemize}
	\item Für systematisches Durchprobieren mittels mehrfach reerfüllbarer Prädikate
	\item Erzeugen von Lösungskandidaten, welche danach getestet werden
	\item Häufiges Entwurfsmuster in Prolog. Zur Vermeidung von kombinatorischen Explosionen: Generator möglichst intelligent machen
	\item Beispiel: \texttt{nat(X) :- nat(Y), X is Y+1.}
\end{itemize}


\subsection{Der Cut (S243)}

\subsubsection{Determinismus (S244)}
Ein Prädikat heißt \textit{deterministisch}, wenn es stets auf höchstens eine Weise erfüllt werden kann; hat es möglicherweise mehrere Lösungen, so heißt es nichtdeterministisch.

In der nichtfunktionalen Welt kann Nichtdeterminismus nur behandelt werden, indem man von Lösungen zu Listen von Lösungen übergeht.

\subsubsection{Beschneiden des Ausführungsbaums}
\begin{itemize}
	\item Die Lösungsfindung kann vorzeitig durch den Programmierer abgebrochen werden ("`Cut"')
	\item Das Einfügen eines Cuts ("`\texttt{!}"') verhindert, dass im Fehlerfall, die Teilziele links davon nicht erneut aufgerufen werden
	\item Beispiel auf Folie 246
\end{itemize}

\subsubsection{Blaue, grüne und rote Cuts (S248)}
\begin{itemize}
	\item \textbf{Blauer Cut}
	\begin{itemize}
		\item Beeinflusst weder Programmlaufzeit noch -verhalten
	\end{itemize}
	\item \textbf{Grüner Cut (S249)}
	\begin{itemize}
		\item Beeinflusst Programmlaufzeit aber nicht -verhalten
		\item Schnellere Ausführung und weniger Speicherbedarf
		\item Beispiel: Einfügen in Funktionen, von denen man weiß, dass sie deterministisch sind
	\end{itemize}
	\item \textbf{Roter Cut (S250)}
	\begin{itemize}
		\item Beeinflusst das Programmverhalten
		\item Werden verwendet, um Wächter zu ersetzen. Ist der erste Wächter erfolgreich, wird der zweite nie angewendet
		\item Können zu erheblichem Effiziensgewinn führen, da sie u.U. sehr komplexe und teure Wächter ersetzen
	\end{itemize}
	\item Faustregel: Der Cut darf erst kommen, wenn man weiß, dass man in der rechtigen Regel ist, aber muss vor der Instanziierung der Ausgabevariablen stehen
	\item Negation: Ein Negationsprädikat ist in Prolog ohne (roten) Cut nicht ausdrückbar
\end{itemize}


\subsection{Unifikation und Resolution (S272)}

\subsubsection{Unifikation (S273)}
\begin{itemize}
	\item Methode zur Vereinheitlichung prädikatenlogischer Ausdrücke\footnote{\url{https://de.wikipedia.org/wiki/Unifikation_(Logik)}}
	\item Ziel: Finde Substitution, die alle Gleichungen erfüllt \(\rightarrow\) "`Unifikator"'
	\item Formaler Algorithmus auf Folie S274, ausführliches Beispiel auf Folie S275
	\item Klammersetzung beachten!
\end{itemize}

\subsubsection{Der Algorithmus}
\begin{itemize}
	\item Eingabe: Eine Liste von Gleichungen
	\item Wiederhole, solange Gleichungen in der Liste
	\begin{enumerate}
		\item Nehme die erste Gleichung und versuche die Variable, die alleine steht, in den anderen Gleichungen zu ersetzen. Steht auf beiden Seiten eine Funktion kann gleichgesetzt werden (Beispiel: \texttt{f(X1, X2) = f(X3, X4) \(\rightarrow\) X1 = X2, X3 = X4}). Beide Gleichungen werden anschließend hinten an der Liste der zu bearbeitenden Gleichungen angefügt
		\item Falls eingesetzt werden konnte, füge die Gleichung einer invertierten Ergebnisliste hinzu. NICHT hinzufügen bei Gleichsetzungen
	\end{enumerate}
	\item Anschließend: Ersetzen der Nichtterminale durch Terminale sowie Zusammenfassen zu einem Ausdruck
\end{itemize}



\section{Grundlagen der Parallelprogrammierung (RE1)}
Motivation: Leistungssteigerung über steigende Taktfrequenzen hinaus. Murphys Gesetz der mangelnden Performance: Jeder Computer ist zu langsam.

\subsubsection{Grundbegriffe}
\begin{itemize}
	\item Race Condition: Ein kritischer Wettlauf ist in der Programmierung eine Konstellation, in der das Ergebnis einer Operation vom zeitlichen Verhalten bestimmter Einzeloperationen abhängt. Im Allgemeinen ist die Möglichkeit, dass eine Race Condition entsteht, zu vermeiden.\footnote{\url{https://de.wikipedia.org/wiki/Race_Condition}}
	\item \textbf{Bedingungen für einen Deadlock\footnote{\url{https://de.wikipedia.org/wiki/Deadlock_\%28Informatik\%29\#Allgemeines}}}
	\begin{enumerate}
		\item No Preemption: Die Betriebsmittel werden ausschließlich durch die Prozesse freigegeben
		\item Hold and Wait: Die Prozesse fordern Betriebsmittel an, behalten aber zugleich den Zugriff auf andere
		\item Mutual Exclusion: Der Zugriff auf die Betriebsmittel ist exklusiv
		\item Circular Wait: Mindestens zwei Prozesse besitzen bezüglich der Betriebsmittel eine zirkuläre Abhängigkeit
	\end{enumerate}
\end{itemize}

\subsubsection{Programmieransätze gemäß der Computerarchitektur (RE11)}
\begin{itemize}
	\item Gemeinsamer Speicher: Jeder Prozessor kann jede Speicherzelle ansprechen (z.B. Multikernrechner)
	\item Verteilter Speicher: Jeder Prozessor hat seinen eigenen Speicher, Kommunikation über \textit{Message Passing} (z.B. bei Computerclustern)
\end{itemize}
Bei sequentieller Programmierung arbeitet der Prozessor nacheinander einzelne Befehle aus dem Arbeitsspeicher ab (von-Neumann-Architektur).

Bei paralleler Programmierung wird in der Theorie häufig das \textit{PRAM-Modell} (RE12) mit einer beliebigen Anzahl an Prozessoren mit
\begin{itemize}
	\item jeweils lokalem Speicher
	\item und synchronem Zugriff auf globalen, gemeinsam genutzten Speicher (in der Praxis eher problematisch bei der Umsetzung)
\end{itemize}
zu Grunde gelegt.

\subsubsection{Flynn's Taxonomy (RE13)}
\begin{enumerate}
	\item \textit{Single Instruction x Single Data:} Klassische von-Neumann-Architektur, ein Befehlsstrom arbeitet auf dem Speicher
	\item \textit{Single Instruction x Multiple Data:} Ein Befehl wird auf gleichartige Daten (z.B. Arrays) angewendet, typischerweise in Vektorprozessoren früherer Supercomputers
	\item \textit{Multiple Instruction x Multiple Data:} Verschiedene Prozessoren arbeiten auf verschiedenen Daten, beispielsweise in heutigen Multicore-Maschinen
	\item \textit{Multiple Instruction x Single Data:} Mehrere Befehle werden gleichzeitig auf den gleichen Daten ausgeführt, beispielsweise in redundanten Architekturen oder in den Pipelines moderner Prozessoren (Ansicht ist umstritten)
\end{enumerate}

\subsubsection{Herausforderungen (RE14)}
\begin{itemize}
	\item Bereits schrittweise Parallelität benötigt Synchronisation
	\item Kommunikation der Prozesse untereinander
	\item Wettlaufbedingungen und Verklemmungen
\end{itemize}
Idealerweise lassen sich Probleme für Parallelverarbeitung so zerlegen, dass sie ohne Abhängigkeiten berechnet werden können; auch stückweise Parallelisierung ist möglich.

\subsubsection{Mögliche Beschleunigung (RE17)}
\begin{itemize}
	\item Speedup: \(S(p) = \frac{T(n,1)}{T(n,p)} = \frac{Aufwand~mit~einem~Prozessor}{Aufwand~mit~p~Prozessoren}\)
	\item Amdahls Gesetz berechnet die maximale Beschleunigung, die durch Parallelverarbeitung erreicht werden kann: \(\frac{1}{(1-P)+\frac{P}{N}}\). \(P\) beziffert den Anteil des Programms, der parallel ausgeführt werden kann
	\item Beispiele in Klausur vom WS2014 und auf Übungsblatt 11
\end{itemize}


\subsection{Fortgeschrittene Konzepte in Java (R21)}
Beispiele befinden sich jeweils bei den entsprechenden Folien.

\subsubsection{Multithreading in Java (RE22)}
\begin{itemize}
	\item Threads vor Java oft eher schwierig zu implementieren (in C/C++ zusätzliche Bibliotheken notwendig)
	\item In Java bereits in der Sprache enthalten
	\item Nicht vorgegeben ist allerdings die interne Implementierung des Multithreading in der jeweiligen VM
	\item Erben von der Klasse \textit{Thread} oder implementieren des Interface \textit{Runnable}
	\item Threads beenden (RE27): \(stop()\) mit Hilfe von Pollen realisiert; ein Thread, der nicht beendet werden will, kann von außen nicht "`sauber"' beendet werden
	\item Rückgabewerte (RE30): Über \(Thread.join()\) realisierbar oder durch die Verwendung von \(Callables\) oder \(Futures\)
	\item Prioritäten (RE31): Threads können mit Hilfe von \texttt{setPriority()} Prioritäten zugewiesen werden
	\item Synchronisation (RE31): Methoden und Blöcke können mit dem Schlüsselwort \texttt{synchronized} vor Unterbrechnung geschützt werden
\end{itemize}

\subsubsection{Java ThreadPools und Executors (RE32)}
\begin{itemize}
	\item Seit Java 5 gibt es eine Reihe von Erleichterungen zur Umsetzung von Parallelität
	\item \texttt{ThreadPools} und \texttt{Executors} ersparen eine eigene Thread-Verwaltung
	\item \texttt{Futures} erlauben die Rückgabe von Ergebnissen (R33)
	\item Ausführliches Beispiel auf Folie 34
\end{itemize}


\subsection{Message Passing Interface (RM1)}
\begin{itemize}
	\item Prozesse mit separaten Speicherbereichen kommunizieren via \textit{Messages}
	\item SIMD: Das selbe Programm wird auf allen Rechnern ausgeführt (RM6)
	\item Jeder Teilnehmer kennt seinen eigenen Rang (ID) und die Anzahl an Teilnehmern (RM5)
	\item Es gibt keinen direkten Master, allerdings wird Prozess 0 per Konvention als "`master control program"' verwendet (RM9)
	\item Die Prozesse können explizit synchronisiert werden, um eine sortierte Ausgabe zu erhalten (RM9)
\end{itemize}

\subsubsection{Übertragen von Nachrichten (RM11)}
\begin{itemize}
	\item Asynchrone oder synchrone Übertragung möglich
	\item \texttt{MPI\_Send} blockiert bis der Nachrichtenpuffer wiederverwendet werden kann
	\item \texttt{MPI\_Recv} blockiert bis die Nachricht komplett gelesen worden ist
	\item Non-blocking ebenfalls möglich, allerdings muss dann zusätzlich überprüft werden, ob die Nachricht vollständig übertragen worden ist (RM18)
	\item Scatter/Gather schicken eine immer gleich große Datenmenge. Die vektorbasierten Funktionen können unterschiedlich große Mengen schicken
\end{itemize}

\subsubsection{Data Distribution (RM19)}
\begin{itemize}
	\item \textbf{Generelles Vorgehen}
	\begin{enumerate}
		\item Verteilen der Daten ("`breakup"')
		\item Durchführen der Berechnungen
		\item Zusammenführen der Ergebnisse
	\end{enumerate}
	\item Spezielle Operationen zum Verteilen und Zusammenführen der Daten
	\item Master-Teilnehmer zum Verteilen und Zusammenführen verantwortlich
	\item Verschiedene Möglichkeiten zum Verteilen und Zusammenführen der Daten. Beispiele ab Folie 22
\end{itemize}


\subsection{Scala (RS1)}

\subsubsection{Überblick (RS3)}
\begin{itemize}
	\item \textit{scalable language} mit kompakterem Code (beispielsweise automatische Getter und Setter)
	\item Erweiterte Unterstützung für Parallelprogrammierung (Actors)
	\item Kompiliert zu Java Bytecode
	\item \textbf{Vergleich zu Java (RS5)}
	\begin{itemize}
		\item Primitive Datentype sind Objekte (vermeided Overhead beim boxing und unboxing)
		\item In beiden Fällen keine Mehrfachvererbung
		\item Compiler erkennt den Typ von Variablen ohne explizite Dekleration
		\item \textit{Traits} (Interfaces) können bereits konkrete Implementierung enthalten
		\item Direkte Integration von Singletons über das Schlüsselwort \texttt{objekt}
		\item Funktional: Funktionen sind First-Class-Objects, Pattern-Matching, Closures, etc)
	\end{itemize}
\end{itemize}

\subsubsection{Referenz}
\begin{itemize}
	\item Variablen können als Konstanten definiert werden (RS8)
	\item \textbf{Klassen und Konstruktoren (RS13)}
	\begin{itemize}
		\item Der primäre Konstruktor definiert impliziert \textit{einige} Getter und Setter (\texttt{.lastName} und \texttt{.lastName =})
		\item Für Parameter ohne explizite Definition als Variable oder Konstante werden nicht als Feld initialisiert und erhalten daher auch weder Getter noch Setter
		\item Uniform Access: Zugriffe werden auf Getter und Setter gemappt (RS14)
	\end{itemize}
	\item Methoden sind vergleichbar mit Java-Methoden, allerdings sind Kurzschreibweisen möglich, da Typen automatisch erkannt werden können (RS15)
	\item Spezifische Getter und Setter: Die Namen von Feldern müssen umbenannt werden (RS16)
	\item Typhierarchie (RS18)
	\item \textbf{Traits (RS19)}
	\begin{itemize}
		\item Vergleichbar zu Java-Interfaces ("`Wesenszug"' oder "`Charaktereigenschaft"')
		\item Können bereits (teilweise) implementiert sein (Vgl. Java-Abstract-Class)
	\end{itemize}
	\item Pattern-Matching: Vgl. mit Java-Switch (RS25)
\end{itemize}

\subsubsection{Parallelität in Scala (RS45)}
\begin{itemize}
	\item Java: Feingranular, threadbasiert
	\item Scala unterstützt die Java API
	\item \textbf{Actors (RS46)}
	\begin{itemize}
		\item Implementierung ähnlich wie bei einem Java-Thread (Erweitern einer Klasse oder per Factory)
		\item Nachrichtenbasierte Kommunikation mit asynchroner, race-freier und non-blocking Warteschlange (RS48)
		\item Implementierung vergleichsweise schwergewichtig, beispielsweise blockiert ein \texttt{receive} den kompletten Thread
		\item Shared-Nothing-Prinzip
	\end{itemize}
	\item \textbf{Futures in Scala (RS52)}
	\begin{itemize}
		\item Konzept: Platzhalter für ein Ergebnis, das später von einem bestimmten Thread ausgefüllt wird
		\item Non-blocking und asynchron \(\rightarrow\) erlaubt Parallelität
	\end{itemize}
\end{itemize}

\subsubsection{Code-Beispiel: Actor}
\begin{minipage}{\linewidth}
\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Scala]
class MyActor extends Actor {
	def act() {
		loop {
			receive {
				// do something fancy and answer to sender
				sender ! "stuff"
			}
		}
	}
}
\end{lstlisting}
\end{minipage}

\subsubsection{Code-Beispiel: Future}
\begin{minipage}{\linewidth}
\begin{lstlisting}[frame=single,numbers=left,mathescape,language=Scala]
val i = 10;
val tasks = for (d <- 0 until b.length()) yield future {
	// do something fancy and return
	// can access elements defined out of the future
	val x = 1000 * i;

	// return as a result
	x;
}

val futuresResult = awaitAll(20000L, tasks: _*);
\end{lstlisting}
\end{minipage}

\subsection{X10}

\subsubsection{Motivation (RX4)}
\begin{itemize}
	\item Parallele Berechnung ist von der Unterstützung der Programmiersprache abhängig
	\item Automatisierte Parallelprogrammierung durch den Compiler funktioniert nicht
	\item Existierende Programmiersprache sind weitestgehend auf Threads limitiert
	\item Programmiersprachen mit direkter Integration 
	\item Anwendungsbeispiel auf Blatt 12, Aufgabe 3
\end{itemize}

\subsubsection{Design}
\begin{itemize}
	\item \textbf{Designziele (RX7)}
	\begin{itemize}
		\item Safety: Vermeidung von typischen Programmierfehlern wie beispielsweise NPE, Initialisierungsfehler, Overflows, etc
		\item Analyzability: Automatische Erkennung von Parallelpfaden innerhalb des Programms
		\item Scalability: Hinzufügen von Prozessoren sollte die Performance verbessern
		\item Flexibility: Unterstützung für verschiedene Parallelentwicklungsansätze
	\end{itemize}
	\item \textbf{Designentscheidungen (RX8)}
	\begin{enumerate}
		\item Neue Programmiersprache: Keine Bibliothek oder Framework
		\item Java als Ausgangspunkt
		\item Einführung des \textit{Partitioned global address space} (PGAS)
		\item Leichtgewichtige Nebenläufigkeit
		\item Unterstützung für große, mehrdimensionale Arrays
	\end{enumerate}
	\item \textbf{Gemeinsamkeiten mit Java (RX9)}
	\begin{itemize}
		\item Klassen und Interfaces mit Einfachvererbeung und Objekthierarchie
		\item Die üblichen Programm- und Kontrollstrukturen
	\end{itemize}
	\item \textbf{Unterschiede gegenüber Java (RX11)}
	\begin{itemize}
		\item Zusätzliche arithmetische Datentypen
		\item Variablen und Konstanten wie in Scala
		\item "`Richtige"' mehrdimensionale Arrays (keine Arrays in Arrays)
		\item Eingeschränkte Typen und Methoden
	\end{itemize}
	\item Structs: Performanter als Objekte, allerdings ohne Vererbung (RX13)
	\item Functions sind First-Class-Objects (RX14)
	\item \textbf{Distribution (RX15)}
	\begin{itemize}
		\item Fundamentale Möglichkeiten zur Datenverteilung
		\item Messages: Message-passing, MPI, Actors
		\item Prozesse/Threads: Gemeinsamer Speicher, OpenMP, Java
		\item Address Space: PGAS, UPC, CAF, Chapel, X10
	\end{itemize}
\end{itemize}

\subsubsection{PGAS (RX17)}
\begin{itemize}
	\item \textbf{Eigenschaften eines PGAS-System}
	\begin{itemize}
		\item Besteht aus einer Menge von Prozessoren und Arbeitsspeicher. Letzterer wird zwischen den Porzessoren aufgeteilt
		\item Es gibt einen Mechanismus, um auf den Speicherbereich anderer Prozessoren zuzugreifen, was allerdings zwangsläufig mit einer Verzögerung verbunden ist
		\item Jede Speicherzelle ist mit einem Thread assoziiert
	\end{itemize}
	\item \textbf{Einfache Parallelität mit async: \texttt{async S} (RX19)}
	\begin{itemize}
		\item Legt eine neue Kind-Activity an, welches das Statement \texttt{S} ausführt und sofort zurückgibt
		\item Kann nicht benannt oder abgebrochen werden
		\item Ersetzt kein \texttt{atomic} bei konkurierendem Zugriff auf ein Objekt!
	\end{itemize}
	\item \textbf{Synchronisation: \texttt{finish S} (RX20)}
	\begin{itemize}
		\item Führt \texttt{S} aus und wartet, bis alle \texttt{asyncs} abgearbeitet worden sind \(\rightarrow\) geschachtelt mit \texttt{async} verwendbar
		\item Nützlich für lokale oder entfernte Daten
	\end{itemize}
	\item \textbf{Isolation: \texttt{atomic S} (RX21)}
	\begin{itemize}
		\item Führt \texttt{S} atomar seriell aus
		\item Vergleichbar mit \texttt{synchronized} in Java
		\item Atomare Blöcke müssen non-blocking und sequentiell sein und müssen auf lokalen daten arbeiten
		\item Diese Einschränkungen werden dynamisch überprüft
	\end{itemize}
	\item \textbf{Conditional Wait: \texttt{when (E) S} (RX22)}
	\begin{itemize}
		\item Die Activity setzt aus, bis der Zustand des Guard \texttt{E} \texttt{true} gesetzt wird
		\item \texttt{S} wird dann atomar ausgeführt
		\item Für den Guard \texttt{E} gelten die selben Eigenschaften, wie für atomare Blöcke
	\end{itemize}
	\item \textbf{Localization: \texttt{at (p) S} (RX23)}
	\begin{itemize}
		\item Leichtgewichtiger Thread ohne eigenen Namen, der asynchron ausgeführt wird
		\item \texttt{S} wird bei \texttt{p} ausgeführt
		\item Während der Ausführung von \texttt{S} wird \texttt{p} blockiert
	\end{itemize}
\end{itemize}



\section{Compiler (S323)}

\subsection{Einführung (S324)}
\begin{itemize}
	\item Reiner Übersetzer: Liest den Quelltext Anweisung für Anweisung; billig; sinnvoll bei Kommandosprachen (Unix-Shell)
	\item Interpretation nach Vorübersetzer: Transformation in eine günstigere Form; nicht unbedingt maschinennah; beispielsweise Java-Bytecode oder Python
	\item Vollständige Übersetzung: Übersetzung in Maschinencode,; Zielsprache beschreibt eine abstrakte Laufzeitmaschine, definiert durch Hardware, Betriebssystem, etc; beispielsweise C/C++ oder Fortran
	\item Just-in-time-Compiler: Übersetzung bedarfsgerecht während der Ausführung; beispielsweise die moderne JVM oder .NET
\end{itemize}


\subsection{Lexikalische Analyse (S332)}
\begin{itemize}
	\item Eingabe: Sequenz von Zeichen
	\item Erkennen von bedeutungstragenden Zeichengruppen (\textit{tokens}) und Überspringen unwichtiger Zeichen (Leerzeichen, Kommentare, etc)
	\item Bezeichner identifizieren und in Stringtabelle zusammenfassen
\end{itemize}

\subsection{Syntaktische Analyse (S333)}
\begin{itemize}
	\item Eingabe: Sequenz von Tokens; Ausgabe; Abstrakter Syntaxbaum
	\item Überprüfen, ob die Eingabe zu kontextfreier Sprache gehört
	\item Erkennen der hierarchischen Struktur der Eingabe
	\item \textbf{\texttt{First}- und \texttt{Follow}-Mengen (S364)}
	\begin{itemize}
		\item First: Die Menge aller Symbole, mit denen ein durch Nichtterminalsymbole abgeleitetes Wort beginnen kann. Leeres Wort (\(\epsilon\)) ggf. nicht vergessen und \texttt{\#} hinzufügen. Wird das erste Element zum leeren Wort abgeleitet, kann auch zu weiteren Terminalen abgeleitet werden (siehe \texttt{PD} in Klausur SS2014, Aufgabe 10)
		\item Follow: Die Menge aller Terminale, die auf das entsprechende Nichtterminal in einem Wort der Sprache folgen können. Wortende nicht vergessen!
		\item Beispiele auf S365, ausführliches Beispiel mit den FOLLOW-Schritten auf Übungsblatt 13
	\end{itemize}
	\item \(SLL_1\)-Bedingung: Die Grammatik muss linksfaktorisiert sein und die Elemente der \(First_1\)-Mengen dürfen exklusiv nur in jeweils einer \(First_1\)-Menge auftreten
\end{itemize}

\subsection{Semantische Analyse (S335)}
\begin{itemize}
	\item Eingabe: Abstrakter Syntaxbaum; Ausgabe: Attributierter Syntaxbaum
	\item \textbf{Kontextsensitive Analyse}
	\begin{itemize}
		\item Namensanalyse: Beziehungen zwischen Deklaration und Verwendung
		\item Typanalyse: Bestimme und prüfe Typen von Variablen, Funktionen, etc.
		\item Konsistenzprüfung: Sind alle Einschränkungen der Programmiersprache eingehalten worden?
	\end{itemize}
	\item Ungültige Programme werden spätestens hier abgelehnt
\end{itemize}

\subsubsection{Zwischencodegenerator (S337)}
\begin{itemize}
	\item Aufgabe: Bringe den Code in sprach- und zielunabhängige Zwischensprache
	\item Optimiere den Code: Konstantenfaltung (Konstanten zusammenfassen), Kopienfortschaltung (setze Werte direkt ein), Code-Verschiebung (Befehle vor statt in einer Schleife ausführen), gemeinsame Teilausdrücke entfernen, Inlining, etc.
\end{itemize}

\subsubsection{Codegenerierung (S338)}
\begin{itemize}
	\item Eingabe: Attributierter Syntaxbaum oder Zwischensprache; Ausgabe: Programm in Assembler oder Maschinencode
	\item \textbf{Erzeuge Code für Zielmaschine}
	\begin{itemize}
		\item Anpassung an Konventionen des Laufzeitsystems
		\item Codeauswahl
		\item Scheduling
		\item Registerallokation
		\item Nachoptimierungen
	\end{itemize}
	\item Danach: Assemblieren und Binden
\end{itemize}


\subsection{Java-Bytecode (S390)}
\begin{itemize}
	\item \textbf{Java-Technologie}
	\begin{itemize}
		\item Bytecode: Portable, plattformunabhängige Zwischensprache
		\item Als virtuelle Maschine mit Laufzeitsystem spezifiziert
		\item Umfangreiche Bibliothek
	\end{itemize}
	\item \textbf{Virtuelle Maschine - Laufzeitsystem (S392)}
	\begin{itemize}
		\item Heap: Speicher für Objektinstanzen, getypt, Garbage Collection, gemeinsamer Speicher für alle Threads
		\item Method Area: Code für Methoden (read-only)
		\item Runtime Constant Pool: Konstante Daten (Literale, Typinformationen, etc)
		\item Threads: Jeweils mit Program Counter, JVM Stack mit Activation Records (Rücksprungadresse, dynamischer Vorgänger, lokale Variablen, Operandenstack) und Native JVM Stack (Laufzeitsystem, meist in C/C++ geschrieben) 
	\end{itemize}
\end{itemize}

\subsubsection{Instruktionen (S395)}
\begin{itemize}
	\item Typen bekannt aus Java
	\item Instuktionen explizit typisiert: \texttt{iadd(int)}, \texttt{fadd(float)}
	\item Instruktionsklassen im Anhang
	\item Beispiel ab S396
\end{itemize}

\subsubsection{Methodenaufrufe (S398)}
Komplettes Beispiel mit Konstantenpool auf S399
\begin{itemize}
	\item Bezugsobjekt auf den Stack (falls nicht \texttt{static})
	\item Parameter auf den Stack
	\item \texttt{invokevirtual} oder \texttt{invokestatic} ausführen (weitere Details hierzu auf der Folie)
	\item \texttt{Return}-Wert vom Stack holen und weiterarbeiten
\end{itemize}

\subsubsection{Deskriptoren (S400)}
Namen von Klassen, Felder und Methoden müssen einem festgelegten Schema entsprechen. Beispiele sind auf der Folie zu finden.

\subsubsection{Objekt erzeugen und initialisieren (S401)}
\begin{itemize}
	\item Objekt anlegen und Speicher reservieren
	\item Danach Objekt initialisieren (Konstruktor aufrufen)
	\item Jede Klasse braucht mindestens den Default-Konstruktor
	\item Beispiel auf der Folie
\end{itemize}

\subsubsection{Weitere Beispiele}
\begin{itemize}
	\item Array anlegen und darauf zugreifen (S402)
	\item Auf Feld zugreifen (S403)
\end{itemize}


\subsection{Codeerzeugung (S404)}

\subsubsection{Umgekehrte polnische Notation (S405)}
\begin{itemize}
	\item Schreibweise für Ausdrücke, bei der zuerst die Operanden und dann die auszuführende Operation angegeben wird
	\item Eindeutig, auch ohne Präzedenzen und Klammern
	\item Natürliche Darstellung für Stackmaschinen. Ermöglicht einfache Übersetzung von Ausdrücken in Byte-Code
	\item Beispiele auf der Folie
	\item \textbf{Erzeugung von UPNs}
	\begin{itemize}
		\item Gegeben: Berechnungsformel als Baum
		\item Postfixordnung bei Tiefensuche erzeugt UPN
		\item Postfixordnung: Ausgabe beim Verlassen eines Knoten, also nach dem Kinder besucht sind
	\end{itemize}
\end{itemize}

\subsubsection{Kontrollstukturen (S408)}
\begin{itemize}
	\item Kontrollstrukturen werden mit bedingten Sprüngen realisiert
	\item \texttt{if} (S408): Labelbereiche mit Sprungbefehlen
	\item \texttt{while} (S409): Aufgeteilt in \texttt{loopheader}, \texttt{loopbody} und \texttt{afterloop}
\end{itemize}

\subsubsection{Codeerzeugung: Bedingte Sprünge (S410)}
\begin{itemize}
	\item Hilfsmethoden zur Umsetzung von Kontrollstrukturen
	\item \texttt{makeLabel();} erzeugt eine neue, eindeutige Sprungmarke
	\item \texttt{evaluateBooleanExpression(expr, trueLabel, falseLabel);} wertet einen Ausdruck aus und springt zur angegebenen Zielmarke
\end{itemize}



\section{Appendix A: Haskell}

\subsection{Funktionen}
\begin{table}[H]
\begin{tabularx}{\textwidth}{l|X|X}
	\textbf{\textit{drop}} & \(Int \rightarrow [a] \rightarrow [a]\) & Gibt die Liste ohne die ersten \textit{n} Elemente zurück \\
	\textbf{\textit{elem}} & \(Eq~a \Rightarrow a \rightarrow [a] \rightarrow Bool\) & Prüft, ob ein Element in einer Liste vorhanden ist \\
	\textbf{\textit{filter}} & \((a \rightarrow Bool) \rightarrow [a] \rightarrow [a]\) & Filtert die Eingabeliste anhand einer Funktion \\
	\textbf{\textit{head}} & \([a] \rightarrow a\) & Gibt das erste Element einer nicht-leeren Liste zurück \\
	\textbf{\textit{isDigit}} & \(Char \rightarrow Bool\) & Erkennt eine Zahl \\
	\textbf{\textit{iterate}} & \((a \rightarrow a) \rightarrow [a] \rightarrow [a]\) & Gibt eine unendliche Liste durch mehrfachausführung einer Funktion zurück \\
	\textbf{\textit{head}} & \([a] \rightarrow a\) & Gibt das erste Element einer Liste zurück \\
	\textbf{\textit{last}} & \([a] \rightarrow a\) & Gibt das letzte Element einer Liste zurück \\
	\textbf{\textit{length}} & \([a] \rightarrow Int\) & Gibt die Länge einer Liste oder eines Texts zurück \\
	\textbf{\textit{map}} & \((a \rightarrow b) \rightarrow [a] \rightarrow [b]\) & Führt eine gegebene Operation auf allen Elementen einer Liste aus \\
	\textbf{\textit{null}} & \([a] \rightarrow Bool\) & Prüft, ob eine Liste leer ist \\
	\textbf{\textit{repeat}} & \(a -> [a]\) & Erzeugt eine unendliche Liste durch Wiederholen des selben Elements \\
	\textbf{\textit{reverse}} & \([a] \rightarrow [a]\) & Gibt eine invertierte Form der Eingabeliste zurück \\
	\textbf{\textit{sort}} & \(Ord~a \Rightarrow [a] \rightarrow [a]\) & Gibt eine sortierte Form der Eingabeliste zurück \\
	\textbf{\textit{sortBy}} & \((a \rightarrow a \rightarrow Ordering) \rightarrow [a] \rightarrow [a]\) & Sortiert anhand einer gegebenen Vergleichsfunktion \\
	\textbf{\textit{tail}} & \([a] \rightarrow [a]\) & Gibt eine Liste ohne Kopfelemente der Eingabeliste (Listenrest) zurück \\
	\textbf{\textit{take}} & \(Int \rightarrow [a] \rightarrow [a]\) & Gibt die ersten \textit{n} Elemente einer Liste zurück \\
	\textbf{\textit{zipWith}} & \((a \rightarrow b \rightarrow c) \rightarrow [a] \rightarrow [b] \rightarrow [c]\) & Kombiniert jeweils die Elemente zweier Listen über eine beliebige Funktion, beispielsweise \textit{(*)} \\
\end{tabularx}
\end{table}


\subsection{Spezielle Listenoperationen}
\begin{itemize}
	\item \texttt{(x:xs)}: Trennt die übergebene Liste in einen Listenkopf \texttt{x} (einelementig) und einen Listenrest \texttt{xs} (kann mehrelementig oder auch leer sein)
	\item \texttt{l ++ x}: Konkateniert die Listen \texttt{l} und \texttt{x}
	\item \texttt{l !! n}: Gibt das \texttt{n}-te Element der Liste \texttt{l} zurück
	\item \texttt{/=}: Ungleich
\end{itemize}


\section{Appendix B: Zahlenkodierungen}

\subsection{Rechnen mit Church-Zahlen (S173)}
\begin{table}[H]
\begin{tabularx}{\textwidth}{l|X}
	Paar & \texttt{pair = \(\lambda\)a. \(\lambda\)b. \(\lambda\)f. f a b} \\
	Erstes Paarelement & \texttt{fst = \(\lambda\)p. p (\(\lambda\)a. \(\lambda\)b. a)} \\
	Zweites Paarelement & \texttt{snd = \(\lambda\)p. (\(\lambda\)a. \(\lambda\)b. b)} \\
	Paarnachfolger & \texttt{next = \(\lambda\)p. pair(snd p)(succ(snd p))} \\
	Nachfolgerfunktion & \texttt{succ = \(\lambda\)n. \(\lambda\)s. \(\lambda\)z. s(n s z)} \\
	Vorgängerfunktion & \texttt{pred = \(\lambda\)n. fst(n next(pair \(c_0\) \(c_0\)))} \\
	Test auf Null & \texttt{isZero = \(\lambda\)n. n (\(\lambda\)x. \(c_{false}\)) \(c_{true}\)} \\
	Addition & \texttt{plus = \(\lambda\)m. \(\lambda\)n. \(\lambda\)s. \(\lambda\)z. m s (n s z)} \\
	Subtraktion & \texttt{sub = \(\lambda\)m. \(\lambda\)m. n pred m} \\
	Multiplikation & \texttt{times = \(\lambda\)m. \(\lambda\)n. \(\lambda\)s. n (m s)} \\
	Potenzierung & \texttt{exp = \(\lambda\)m. \(\lambda\)n. n m} \\
	Vergleichsoperator \texttt{(<=)} & \texttt{lessEq = \(\lambda\)m. \(\lambda\)n. isZero(sub n m)} \\
\end{tabularx}
\end{table}



\section{Appendix C: Typherleitungsregeln (S195)}

\subsection{Regeln für Typschemata}

\subsubsection{\texttt{CONST}}
\[CONST:~\frac{c \in Const}{\Gamma \vdash c~:~\tau_c}\]

\subsubsection{\texttt{VAR}}
\[VAR:~\frac{\Gamma(x)=\tau}{\Gamma \vdash x~:~\tau},~Constrait: \frac{\alpha_1~\alpha_2}{} \Rightarrow \alpha_1 = \alpha_2\]

\subsubsection{\texttt{ABS}}
\[ABS:~\frac{\Gamma,x~:~\tau_1 \vdash t~:~\tau_2}{\Gamma \vdash \lambda x.t~:~\tau_1 \rightarrow \tau_2},~Constrait: \frac{\alpha_2~\alpha_3}{\alpha_1} \Rightarrow \alpha_1 = \alpha_2 \rightarrow \alpha_3\]

\subsubsection{\texttt{APP}}
\[APP:~\frac{\Gamma \vdash t_1~:~\tau_2 \rightarrow \tau~~~~~~~\Gamma\vdash t_2~:~\tau_2}{\Gamma\vdash t_1t_2~:~\tau},~Constrait: \frac{\alpha_2~\alpha_3}{\alpha_1} \Rightarrow \alpha_2 = \alpha_3 \rightarrow \alpha_1\]


\subsection{Angepasste Regeln für Typschemata}
\texttt{CONST}- und \texttt{APP}-Regeln bleiben gleich.

\subsubsection{\texttt{VAR} (S203)}
\[VAR:~\frac{\Gamma(x)=\tau~~~~~~~\tau'\succeq\tau}{\Gamma \vdash x~:~\tau}\]

\subsubsection{\texttt{ABS} (S203)}
\[ABS:~\frac{\Gamma,x~:~\tau_1 \vdash t~:~\tau_2~~~~~~~\tau_1~kein~Typschema}{\Gamma \vdash \lambda x.t~:~\tau_1 \rightarrow \tau_2}\]

\subsubsection{\texttt{LET} (S205)}
\[LET:~\frac{\Gamma \vdash t_1~:~\tau_1~~~~~~~\Gamma,x~:~ta(\tau_1,\Gamma)\vdash t_2~:~\tau_2}{\Gamma \vdash let~x=t_1~in~t_2~:~\tau_2}\]



\section{Appendix D: Prolog-Funktionen}
\begin{table}[H]
\begin{tabularx}{\textwidth}{l|X|X}
	\textbf{\textit{append}} & \texttt{append(L1, L2, R)} & Konkateniert zwei Listen \\
	\textbf{\textit{even}} & \texttt{even(X)} & Prüft, ob \texttt{X} gerade ist \\
	\textbf{\textit{member}} & \texttt{member(X, L)} & Prüft ob \texttt{X} in \texttt{L} enthalten ist \\
	\textbf{\textit{mod}} & \texttt{X is mod(Y, Z)} & Berechnet \texttt{Y mod Z} \\
	\textbf{\textit{not}} & \texttt{not()} & Invertiert den Eingabeausdruck \\
	\textbf{\textit{odd}} & \texttt{odd(X)} & Prüft, ob \texttt{X} ungerade ist \\
	\textbf{\textit{rev}} & \texttt{rev(L, R)} & Invertiert die Eingabeliste \\
\end{tabularx}
\end{table}



\section{Appendix E: MPI}
\begin{itemize}
	\item \textbf{\texttt{MPI\_Send} (RM11)}
	\begin{itemize}
		\item Synchrone Punkt-zu-Punkt Kommunikation
		\item \texttt{int MPI\_Send(void* buf, int count, MPI\_Datatype datatype, int dest, int tag, MPI\_Comm comm)}
	\end{itemize}
	\item \textbf{\texttt{MPI\_Recv} (RM12)}
	\begin{itemize}
		\item Synchrone Punkt-zu-Punkt Kommunikation
		\item \texttt{int MPI\_Recv(void* buf, int count, MPI\_Datatype datatype, int source, int tag, MPI\_Comm, MPI\_Status *status)}
	\end{itemize}
	\item \textbf{\texttt{MPI\_Bcast}: Streuen (RM20)}
	\begin{itemize}
		\item Ein ausgewählter MPI-Prozess \textit{root} schickt allen anderen Prozessen in seiner Gruppe \textit{comm} die gleichen Daten
		\item Die dafür definierte Funktion ist dabei für alle beteiligten Prozesse identisch
		\item \texttt{int MPI\_Bcast(void* buf, int count, MPI\_Datatype t, int root, MPI\_Comm comm)}
		\item Implementiert in Klausur WS2012
	\end{itemize}
	\item \textbf{\texttt{MPI\_Scatter}: Streuen (RM23)}
	\begin{itemize}
		\item Der MPI Prozess \textit{root} jedem beteiligten Prozess ein unterschiedliches, aber gleich großes Datenelement
		\item \texttt{MPI\_Scatterv} erlaubt das vektorbasierte Senden von unterschiedlicher Datengröße (RM24)
		\item \texttt{int MPI\_Scatter(void* sendbuf, int sendcount, MPI\_Datatype sendtype, void* recvbuf, int recvcount, MPI\_Datatype recvtype, int root, MPI\_Comm comm)}
		\item Implementiert in Klausur SS2015
	\end{itemize}
	\item \textbf{\texttt{MPI\_Gather}: Sammeln (RM25)}
	\begin{itemize}
		\item Der MPI-Prozess sammelt \textit{root} die Daten aller beteiligten Prozesse ein
		\item Die Daten aller Sendepuffer werden dabei (nach Rang sortiert) hintereinander im Empfangspuffer abgelegt
		\item Vektorbasierte Variante vorhanden
		\item \texttt{int MPI\_Gather(void* sendbuf, int sendcount, MPI\_Datatype sendtype, void* recvbuf, int recvcount, MPI\_Datatype recvtype, int root, MPI\_Comm comm)}
	\end{itemize}
	\item \textbf{\texttt{MPI\_Allgather} (RM27)}
	\begin{itemize}
		\item Jeder Prozess schickt an jeden anderen Prozess die gleichen Daten
		\item Multi-Broadcast-Operation, bei der es keinen gesonderten MPI-Prozess gibt
		\item Im Anschluss hält der Buffer von jedem Prozess in \textit{comm} die selben Daten in der selben Reihenfolge (inklusiv der eigenen)
		\item \texttt{int MPI\_Allgather(void* sendbuf, int sendcount, MPI\_Datatype sendtype, void* recvbuf, int recvcount, MPI\_Datatype recvtype, MPI\_Comm comm)}
	\end{itemize}
	\item \textbf{\texttt{MPI\_Alltoall} (RM28}
	\begin{itemize}
		\item Datenaustausch zwischen allen Prozessen
		\item Nur der i-te Teil des Sendebuffers wird an den i-ten Prozess gesendet, Daten, die vom Prozess mit dem Rang j kommen, werden entsprechend an j-ter Stelle im Empfangsbuffer gespeichert
		\item Die Funktion kehrt erst zurück, nachdem alle in der angegebenen Gruppe befindlichen MPI-Prozesse diesen Teil des Programmes erreicht haben
		\item \texttt{int MPI\_Alltoall(void* sendbuf, int sendcount, MPI\_Datatype sendtype, void* recvbuf, int recvcount, MPI\_Datatype recvtype, MPI\_Comm comm)}
	\end{itemize}
	\item \textbf{\texttt{MPI\_Reduce} (RM29)}
	\begin{itemize}
		\item Spezielle Form der Gather-Operation
		\item Es werden ebenfalls die Daten aller beteiligten Prozesse aufgesammelt, aber zusätzlich noch mittels einer festgelegten Reduktionsoperation zu einem Datum reduziert
		\item Arithmetische und logische Operationen verfügbar (siehe Folie)
		\item \texttt{int MPI\_Reduce(void* sendbuf, void* recvbuf, int count, MPI\_Datatype type, MPI\_Op op, int root, MPI\_Comm comm)}
		\item Implementiert für \texttt{SUM} in Klausur SS2013
	\end{itemize}
\end{itemize}



\section{Appendix F: Bytecode}

\subsection{Instruktionsklassen (S395)}
\begin{itemize}
	\item Lesen/Schreiben von lokalen Variablen: \texttt{?load, ?store <x>, ...}
	\item Lesen/Schreiben von Feldern: \texttt{getfield, putfield, ...}
	\item Sprungbefehle: \texttt{ifeq, ifnull, tableswitch, ...}
	\item Methodenaufrufe mit Funktionen aus dem Konstantenpool an Stelle \texttt{n}: \texttt{invokevirtual \#N, invokestatic \#N, ...}
	\item Objekterzeugung: \texttt{new, newarray, ...}
	\item Arithmetische Berechnung: \texttt{?mul, ?add, ...}
\end{itemize}

\subsection{Ladebefehle}
\begin{itemize}
	\item Laden von Konstanten: \texttt{ldc}
	\item Laden von lokalen Variablen: \texttt{iload\_N}
	\item Laden vom \texttt{this}-Pointer: \texttt{aload\_N}. Steht meist an nullter Stelle
\end{itemize}

\subsection{Kontrollstrukturen}
\begin{itemize}
	\item Bedingter Sprung: \texttt{if\_icmpgt [Sprungziel], if\_icmplt [Sprungziel]}
	\item Unbedingter Sprung: \texttt{goto [Sprungziel]}
\end{itemize}